---
title: "Remote Network Calibration"
author: "Audrey Smith"
date: "6/9/2020"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
library(httr)
library(jsonlite)
library(dplyr)
library(tidyr)
library(lubridate)
library(ggplot2)
```

_Get Data for Comparison_

# Read in test data - code for PSE data below
proxy_existing <- read.csv('proxy_data/proxy_data_all.csv', stringsAsFactors = F)
proxy_all <- proxy_existing

aqy_data_full <- read.csv('test_data/test_driftTypes.csv', stringsAsFactors = F)
aqy_data_cal <- rename(aqy_data_full, 'O3_cal'='value', 'Time'='timestamp')
cal_params_full <- mutate(aqy_data_cal, start_date = '2019-12-05', end_date = '9999-12-31', O3.slope = 1, O3.offset = 0, proxy_site = 'San Pablo') %>%
  dplyr::select(ID, proxy_site, O3.slope, O3.offset, start_date, end_date) %>%
  unique()
  
* Later - to add content to identify and download missing data for dates in question
```{r}
### DOWNLOAD PROXY DATA ###
# Determine which dates we already have versus which dates we need
proxy_existing <- read.csv('proxy_data/proxy_data_all.csv', stringsAsFactors = F)
existing_dates <- sort(unique(as_date(proxy_existing$timestamp)), decreasing = T)

start_date <- existing_dates[1]+1 # First date needed is first date not in existing data
end_date <- Sys.Date()-1 # Last date needed is yesterday

# Request recent proxy data
request_url = paste0('http://www.airnowapi.org/aq/data/?startDate=', start_date, 'T00&endDate=', end_date, 'T23&parameters=OZONE,PM25,NO2&BBOX=-122.720038,37.701918,-121.965229,38.126622&dataType=C&format=application/json&verbose=0&nowcastonly=0&includerawconcentrations=1&API_KEY=C05358E3-5508-4216-A03E-E229E0368B7E')
 
request_call <- GET(url = request_url)
stop_for_status(request_call)
  
request_json <- content(request_call, as = 'text', type = NULL, encoding = 'UTF-8')
request_df <- arrange(fromJSON(request_json, simplifyDataFrame = TRUE), desc(UTC))

# Join with station names and clean column names
reg_names <- read.csv('spatial/monitor_shp_named.csv') %>% dplyr::select(-X)
reg_data <- inner_join(request_df, reg_names, by = c('Latitude'='monitor_lat', 'Longitude'='monitor_long'))
reg_data$timestamp <- as_datetime(paste(substr(reg_data$UTC, 1, 10), substr(reg_data$UTC, 12, 16), ':00'))
requested_dates <- unique(as_date(reg_data$timestamp))

reg_data <- dplyr::select(reg_data, -c(UTC)) %>% 
  rename('lat'='Latitude', 'lon'='Longitude', 'modality'='Parameter', 'units'='Unit', 'value'='Value', 'original_value'='RawConcentration', 'installation_site_name' = 'monitor_names') 

# Append new data to existing data if not already included
for(i in 1:length(requested_dates)){
  if(requested_dates[i] %in% existing_dates){requested_dates <- c(requested_dates[-i])} # If date already included, remove from dates to append
  else{requested_dates <- requested_dates} # If date not already included in proxy data, do nothing
    }
  
proxy_new <- filter(reg_data, as_date(timestamp) %in% requested_dates) # Filter requested data to data not already in proxy data
proxy_all <- as.data.frame(rbind(proxy_new, proxy_existing)) %>% # Combine new proxy data with existing
  arrange(desc(timestamp)) %>%
  mutate(original_value = ifelse(original_value == -999, value, original_value)) # Fill NAs in raw value

write.csv(proxy_all, 'proxy_data/proxy_data_all.csv', row.names = F)
```

```{r}
### READ IN PSE DATA
# PSE data
aqy_data_full <- read.csv('C:/Users/18313/Desktop/airMonitoring/downloader/results/concatenated_data/PSE_AQY_2019-12-06_2020-06-29_freq_60.csv', stringsAsFactors = F)
aqy_data_full$timestamp <- as_datetime(aqy_data_full$Time)

# Current calibration parameters
cal_params_full <- read.csv('results/cal_params.csv', stringsAsFactors = F) %>% 
  filter(!is.na(lat)) # Filter out undeployed monitors
cal_params_full$start_date <- as.Date(cal_params_full$start_date, '%m/%d/%Y')
cal_params_full$end_date <- as.Date(cal_params_full$end_date, '%m/%d/%Y')


#Calibrating using applicable parameters for date parameters
aqy_data_cal <- inner_join(cal_params_full, aqy_data_full, by = 'ID') %>%
  mutate(end_date = ifelse(is.na(end_date), '9999-12-31', end_date)) %>% 
  filter(timestamp >= start_date & timestamp <= end_date) %>% # Filter out rows with calibration parameters that do not apply
  mutate(PM_cal = PM.gain*(PM2.5-PM.offset), 
         O3_cal = O3.gain*(O3-O3.offset), 
     NO2_cal = NO2.gain*((Ox.gain*(Ox-Ox.offset)-1.1*O3_cal)-NO2.offset))
```


# Identifying deployed AQYs that did not show up in last 72 hours
  #aqy_deployed <- dplyr::select(cal_params, ID) %>% unique() #filter(cal_params, start_date >= start_72 & end_date <= end_72) %>% dplyr::select(ID)
  #aqy_list <- unique(dplyr::select(aqy_data_cal, ID))
  
  #aqy_missing <- pull(anti_join(aqy_deployed, aqy_list, by = 'ID'), ID) # Deployed monitors missing from time frame
 # print(paste('There were', nrow(aqy_list), 'AQY monitors online over the last 72 hours. Compare to', nrow(aqy_deployed), 'deployed monitors. These monitors may be offline:'))
 # print(aqy_missing)
  
  # Identifying monitors with extreme values
  #aqy_extreme <- group_by(aqy_data_cal, ID) %>%
    #summarize(O3_mean = mean(O3_cal)) %>%
    #filter(O3_mean < 0 | O3_mean >= 350)
  
  #print(paste('Extreme values were observed at:', aqy_extreme))
  
_Ozone Drift Detection and Recalibration_
```{r}
### GENERATE FLAGS AND CALIBRATION PARAMETERS
recalibrate_O3 <- function(start_72, end_72){
    
    ### DRIFT DETECTION
        # Filter data to appropriate time, location, and pollutant
        reg_O3 <- filter(proxy_all, modality == 'OZONE' & timestamp >= start_72 & timestamp <= end_72)
        
        aqy_O3 <- filter(aqy_data_cal, Time >= start_72 & Time <= end_72)
        aqy_O3_id <- dplyr::select(aqy_O3, ID) %>% unique()
        
        # Initialize blank dataframes for flags, results
        todays_flags <- mutate(aqy_O3_id, ks_O3 = 0, slope_O3 = 0, offset_O3 = 0)
        
        # Generate flags by monitor
        for(i in 1:nrow(aqy_O3_id)){
            # Filter to the AQY we would like to test for drift
            aqy_O3_select <- filter(aqy_O3, ID == aqy_O3_id[i,1])
            aqy_ID <- unique(aqy_O3_select$ID)
            
            # Filter to appropriate proxy
            proxy_stn <- unique(aqy_O3$proxy_site)
            
            proxy_O3 <- filter(reg_O3, installation_site_name %in% proxy_stn)
            
              # Throw error if insufficient proxy data to compare distributions
              if(nrow(proxy_O3) < .5*nrow(aqy_O3_select)){
                stop(print(paste('Insufficient proxy data for', aqy_ID, 'nrow =', nrow(proxy_O3)))) }
          
            #Averaging by hour - uncomment when using PSE data
            #aqy_O3_select$day_hour <- paste(day(aqy_O3_select$Time), hour(aqy_O3_select$Time)) # Generate column with unique ID for day/hour
            #aqy_O3_60 <- group_by(aqy_O3_select, ID, day_hour) %>% 
            #summarize(value = mean(O3_cal), na.rm = T)
            
            aqy_O3_60 <- aqy_O3_select %>% 
              rename('value'='O3_cal')
            
            ## Flag via ks test
            ks_results <- suppressWarnings(ks.test(proxy_O3$original_value, aqy_O3_60$value, exact = F))
            ks_p <- ks_results$p.value # Get p-value from KS test
            
            todays_flags$ks_O3[i] <- ifelse(ks_p <= 0.05, 1, 0)
            
            
            ## Flag results via mean-variance moment matching
            # Slope drift
            var_aqy <- var(aqy_O3_60$value, na.rm = T)
            var_reg <- var(proxy_O3$original_value, na.rm = T)
            
            manual_slope <- sqrt(var_reg/var_aqy)
            
            todays_flags$slope_O3[i] <- ifelse(manual_slope > 1.3 | manual_slope < .7, 1, 0) # Assign flag if manual slope outside bounds
            
            # Offset drift
            mean_aqy <- mean(aqy_O3_60$value, na.rm = T)
            mean_reg <- mean(proxy_O3$original_value, na.rm = T)
            
            manual_offset <- mean_reg - mean_aqy*manual_slope
            
            todays_flags$offset_O3[i] <- ifelse(manual_offset > 5 | manual_offset < -5, 1, 0) # Assign flag if manual offset outside bounds
            
            ## Print parameters
            print(paste(aqy_ID, '|| KS P-VALUE:', ks_p, '| MANUAL SLOPE:', manual_slope, '| MANUAL OFFSET:', manual_offset))
          }
        
        # Combine today's flags with existing flags
        running_flags <- read.csv('results/running_flags.csv') %>% 
        full_join(., todays_flags, by = 'ID') %>% #Combine running flags with today's flags
        mutate(ks_O3_run = ifelse(ks_O3 == 0, 0, ks_O3_run + ks_O3),
               slope_O3_run = ifelse(slope_O3 == 0, 0, slope_O3_run + slope_O3),
               offset_O3_run = ifelse(offset_O3 == 0, 0, offset_O3_run + offset_O3))
        
        dplyr::select(running_flags, c(ID, ks_O3_run, slope_O3_run, offset_O3_run)) %>%
          write.csv('results/running_flags.csv', row.names = F)
    
    ### RECALIBRATION
    # Identify monitors needing recalibration, using highest of flagged columns
    running_flags$max_flag <- apply(MARGIN = 1, X = running_flags[grep('*_run', colnames(running_flags))], FUN = max)
    needs_calibration <- pull(filter(running_flags, max_flag >= 5), ID)
    
    if(length(needs_calibration) == 0){
      print('No monitors needed recalibration today. Current calibration parameters remain valid.')
      return(running_flags)
      }
      else{
    
        # Recalibrate using last eight days of data (all data included in 72-hr averages for last five days)
        start_recal <- end_72-8
        end_recal <- end_72
        
        flag_detected <- end_72-5
        
        aqy_recal <- filter(aqy_data_full, ID %in% needs_calibration & timestamp >= start_recal & timestamp <= end_recal) # AQY data for recalibration
        
        proxy_recal <- filter(proxy_all, timestamp >= start_recal & timestamp <= end_recal) # Proxy data for recalibration
        
        
        # Blank dataframe for new parameters
        new_params <- as.data.frame(needs_calibration) %>%
          rename('ID'='needs_calibration') %>%
          mutate(proxy_site = 'San Pablo', O3.slope = NA, O3.offset = NA, start_date = as.character(flag_detected), end_date = '9999-12-31') # Fix proxy site portion later
        
        for(i in 1:length(needs_calibration)){
          
          # Isolate AQY data for recalibration period
          aqy_recal_O3 <- filter(aqy_recal, ID == needs_calibration[i])
          #aqy_recal_O3$day_hour <- paste(day(aqy_recal_O3$Time), hour(aqy_recal_O3$Time))
          #aqy_recal_O3 <- group_by(aqy_recal_O3, day_hour) %>%
            #summarize(O3_raw = mean(O3))
          
          aqy_recal_mean <- mean(aqy_recal_O3$O3, na.rm = T)
          aqy_recal_var <- var(aqy_recal_O3$O3, na.rm = T)
          
          # Isolate proxy data for recalibration period
          proxy_recal_O3 <- filter(proxy_recal, installation_site_name == 'San Pablo' & modality == 'OZONE') # Fix later so it also does Berkeley where appropriate
          
          proxy_recal_mean <- mean(proxy_recal_O3$original_value, na.rm = T)
          proxy_recal_var <- var(proxy_recal_O3$original_value, na.rm = T)
          
          new_params$O3.slope[i] <- sqrt(proxy_recal_var/aqy_recal_var)
          new_params$O3.offset[i] <- proxy_recal_mean - new_params$O3.slope[i]*aqy_recal_mean
        }
        
        param_info <- dplyr::select(cal_params_full, ID, description, address, city, lat, long)
        
        param_new_O3 <- left_join(new_params, param_info, by = 'ID') %>%
          dplyr::select(ID, description, address, city, proxy_site, lat, long, O3.slope, O3.offset, start_date, end_date)
       
        param_path <- list.files('results', 'cal_params_O3*')
        param_path_current <- param_path[length(param_path)]
        
        param_existing_O3 <- read.csv(paste0('results/',param_path_current), stringsAsFactors = F) %>%
          dplyr::select(cal_params_full, ID, description, address, city, proxy_site, lat, long, O3.slope, O3.offset, start_date, end_date) #Need to add something to update end date
        
        running_params <- rbind(param_new_O3, param_existing_O3) %>%
          arrange(ID, start_date)
        print(running_params)
        
        write.csv(running_params, paste0('results/cal_params_O3_', end_recal, '.csv'))
                  
        return(running_params)
      }
    
}

#end <- Sys.Date()-203 ## To run for all 72-hour periods back to December
#start <- Sys.Date()-205

end_dates <- seq(Sys.Date()-27, Sys.Date()-1, 1)
start_dates <- seq(Sys.Date()-29, Sys.Date()-3, 1)

for(i in 1:length(start_dates)){
    recalibrate_O3(start_dates[i], end_dates[i])
}

```


_NO2 drift detection and re-calibration_
```{r}


```








































